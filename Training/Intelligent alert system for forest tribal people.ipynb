{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect the dataset from the below link\n",
    "https://www.kaggle.com/arbethi/wild-animal-detection-and-alerting-system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import ImageDataGenerator Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import ImageDataGenerator Library\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#Define the parameters /arguments for ImageDataGenerator class\n",
    "train_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.2,\n",
    "        rotation_range=180,zoom_range=0.2,horizontal_flip=True)\n",
    "\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying ImageDataGenerator functionality to trainset and testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying ImageDataGenerator functionality to trainset\n",
    "x_train=train_datagen.flow_from_directory(\n",
    "    directory= r\"E:\\dataset\\train_set\",\n",
    "    target_size=(64,64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "#Applying ImageDataGenerator functionality to test set\n",
    "x_test=test_datagen.flow_from_directory(\n",
    "    directory= r\"E:\\dataset\\test_set\",\n",
    "    target_size=(64,64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the model building libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Importing the model building libraries'''\n",
    "#to define linear initializations import Sequential\n",
    "from keras.models import Sequential\n",
    "#To add layers import Dense\n",
    "from keras.layers import Dense\n",
    "# to create a convolution kernel import Convolution2D\n",
    "from keras.layers import Convolution2D\n",
    "# Adding Max pooling Layer\n",
    "from keras.layers import MaxPooling2D\n",
    "# Adding Flatten Layer\n",
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the model\n",
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Convolutional Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding CNN layers\n",
    "model.add(Convolution2D(32,(3,3),input_shape=(64,64,3),\n",
    "                        activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Max pooling Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Max pooling Layer\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Flatten Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Flatten Layer\n",
    "model.add(Flatten()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Hidden Layers\n",
    "model.add(Dense(init='uniform',activation='relu',units=300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding 2nd hidden layer\n",
    "model.add(Dense(init='uniform',activation='relu',units=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding 3rd hidden layer\n",
    "model.add(Dense(init='uniform',activation='relu',units=60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding output layer\n",
    "model.add(Dense(init='uniform',activation='softmax',units=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure the learning process or compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the learning process\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "model.fit_generator(x_train,steps_per_epoch=31,\n",
    "                    epochs=15,\n",
    "                    validation_data=x_test,\n",
    "                    validation_steps=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the trained the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model \n",
    "model.save('alert.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random image prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#import numpy library\n",
    "import numpy as np\n",
    "#import load_model method to load our saved model\n",
    "from keras.models import load_model\n",
    "#import image from keras.preprocessing\n",
    "from keras.preprocessing import image\n",
    "#loading our saved model file\n",
    "model = load_model(\"alert.h5\")\n",
    "img = image.load_img(r\"E:\\Guided Projects\\domestic\\cat.4003.jpg\",\n",
    "                     target_size=(64,64))\n",
    "\n",
    "x = image.img_to_array(img)\n",
    "#expanding the shape of image to 4 dimensions\n",
    "x = np.expand_dims(x,axis=0)\n",
    "pred = model.predict_classes(x)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Video streaming and alerting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import opencv\n",
    "import cv2\n",
    "#import numpy\n",
    "import numpy as np\n",
    "from keras.preprocessing import image \n",
    "from keras.models  import load_model\n",
    "#import Client from twilio API\n",
    "from twilio.rest import Client\n",
    "#import playsound package\n",
    "from playsound import playsound\n",
    "\n",
    "#Load saved model file using load_model method\n",
    "model = load_model('alert.h5')\n",
    "#To read webcam\n",
    "video = cv2.VideoCapture(0)\n",
    "#Type of classes or names of the labels that we considered\n",
    "name = ['Human','Domestic', 'Wild']\n",
    "#To execute the program repeatedly using while loop   \n",
    "while(1):\n",
    "    success, frame = video.read()\n",
    "    cv2.imwrite(\"image.jpg\",frame)\n",
    "    img = image.load_img(\"image.jpg\",target_size = (64,64))\n",
    "    x  = image.img_to_array(img)\n",
    "    x = np.expand_dims(x,axis = 0)\n",
    "    pred = model.predict_classes(x)\n",
    "    p = pred[0]\n",
    "    print(pred)\n",
    "    cv2.putText(frame, \"predicted  class = \"+str(name[p]), (100,100), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 1)\n",
    "    \n",
    "    pred = model.predict_classes(x)\n",
    "    if pred[0]==2:\n",
    "        #twilio account ssid\n",
    "        account_sid = 'xxxxxxb550b1c2bfc05353'\n",
    "        #twilo account authentication toke\n",
    "        auth_token = 'xxxxxxc17abba1e1de952d4b4'\n",
    "        client = Client(account_sid, auth_token)\n",
    "\n",
    "        message = client.messages \\\n",
    "        .create(\n",
    "         body='Danger!. Wild animal is detected, stay alert',\n",
    "         from_=' +15035xxxx', #the free number of twilio\n",
    "         to='+91xxxxxxxxx')\n",
    "        print(message.sid)\n",
    "        print('Danger!!')\n",
    "        print('Animal Detected')\n",
    "        print ('SMS sent!')\n",
    "        playsound(r'C:\\Users\\DELL\\Downloads\\Tornado_Siren_II-Delilah-0.mp3')\n",
    "        #break\n",
    "    else:\n",
    "        print(\"No Danger\")\n",
    "       #break\n",
    "    cv2.imshow(\"image\",frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('a'): \n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Video Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "#import facevec\n",
    "import numpy as np\n",
    "from keras.preprocessing import image \n",
    "from keras.models  import load_model\n",
    "\n",
    "model = load_model('alert.h5') \n",
    "video = cv2.VideoCapture(0)\n",
    "name = [\"Human\",\"Wild aniaml\",\"otimher\"]\n",
    "    \n",
    "while(1):\n",
    "    success, frame = video.read()\n",
    "    cv2.imwrite(\"image.jpg\",frame)\n",
    "    img = image.load_img(\"image.jpg\",target_size = (64,64))\n",
    "    x  = image.img_to_array(img)\n",
    "    x = np.expand_dims(x,axis = 0)\n",
    "    pred = model.predict_classes(x)\n",
    "    p = pred[0]\n",
    "    print(pred)\n",
    "    cv2.putText(frame, \"predicted  class = \"+str(name[p]), (100,100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 1)\n",
    "    cv2.imshow(\"image\",frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('a'): \n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
